{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6cda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed5762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(dataset_name, batch_size=128):\n",
    "    print(f\"Loading {dataset_name}...\")\n",
    "    ds = {\n",
    "        'mnist': datasets.MNIST,\n",
    "        'cifar': datasets.CIFAR10\n",
    "    }\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    train_dataset = ds[dataset_name]('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = ds[dataset_name]('./data', train=False, transform=transform)\n",
    "\n",
    "    input_shape = (1, 28, 28) if dataset_name == 'mnist' else (3, 32, 32)\n",
    "    num_classes = 10\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader, input_shape, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832d47c1-b699-4bda-8624-1daa37c16208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CifarNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 512)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dde7628-9246-4f85-b3ff-f0ee6f3d0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ' \n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "def build_and_train(dataset_name, train_loader, epochs=5):\n",
    "    device = torch.device(\"cpu\") # Force CPU for consistency\n",
    "    \n",
    "    if dataset_name == 'mnist':\n",
    "        model = MnistNet().to(device)\n",
    "    else:\n",
    "        model = CifarNet().to(device)\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model_path = f\"model_torch_{dataset_name}.pth\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading existing model: {model_path}\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        print(\"Starting training...\")\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train(model, device, train_loader, optimizer, epoch)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Model saved.\")\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa47dcf9-3abf-4ac8-9f28-d5a5bf3c072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onnx(model, dataset_name, input_shape):\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, *input_shape)\n",
    "    output_path = f\"model_torch_{dataset_name}.onnx\"\n",
    "    \n",
    "    print(f\"Exporting to ONNX: {output_path}\")\n",
    "    torch.onnx.export(model, \n",
    "                      dummy_input, \n",
    "                      output_path, \n",
    "                      verbose=False,\n",
    "                      input_names=['input'], \n",
    "                      output_names=['logits'], # Renamed to 'logits' to be clear\n",
    "                      dynamic_axes={'input': {0: 'batch_size'}, 'logits': {0: 'batch_size'}})\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96362923-1d6d-4315-9f8a-229b9d98ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_models(model, onnx_path, test_loader, input_shape, batch_sizes=[1, 8, 32, 128]):\n",
    "    print(f\"\\nBenchmarking PyTorch vs ONNX ({onnx_path})\")\n",
    "    \n",
    "    # ONNX Session\n",
    "    sess_options = ort.SessionOptions()\n",
    "    session = ort.InferenceSession(onnx_path, sess_options, providers=['CPUExecutionProvider'])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    # Grab chunk of data\n",
    "    all_data = []\n",
    "    for data, _ in test_loader:\n",
    "        all_data.append(data)\n",
    "        if len(all_data) * test_loader.batch_size > 200:\n",
    "            break\n",
    "    x_test = torch.cat(all_data, dim=0) \n",
    "    \n",
    "    results = []\n",
    "    print(f\"{ 'Batch Size':<12} | { 'PyTorch (ms)':<15} | { 'ONNX (ms)':<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    for bs in batch_sizes:\n",
    "        batch_data = x_test[:bs]\n",
    "        if batch_data.shape[0] < bs:\n",
    "            padding = torch.zeros(bs - batch_data.shape[0], *input_shape)\n",
    "            batch_data = torch.cat([batch_data, padding], dim=0)\n",
    "            \n",
    "        # 1. PyTorch Benchmark\n",
    "        with torch.no_grad():\n",
    "            # Warmup\n",
    "            _ = model(batch_data)\n",
    "            start = time.time()\n",
    "            for _ in range(10):\n",
    "                _ = model(batch_data)\n",
    "            end = time.time()\n",
    "            torch_time = (end - start) / 10 * 1000\n",
    "            \n",
    "        # 2. ONNX Benchmark\n",
    "        numpy_data = batch_data.numpy()\n",
    "        # Warmup\n",
    "        session.run(None, {input_name: numpy_data})\n",
    "        start = time.time()\n",
    "        for _ in range(10):\n",
    "            session.run(None, {input_name: numpy_data})\n",
    "        end = time.time()\n",
    "        onnx_time = (end - start) / 10 * 1000\n",
    "        \n",
    "        print(f\"{bs:<12} | {torch_time:<15.4f} | {onnx_time:<15.4f}\")\n",
    "        results.append((bs, torch_time, onnx_time))\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8e815d-21f0-495f-b19c-3660c0daf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_accuracy_and_soft(model, onnx_path, test_loader, num_samples=5):\n",
    "    print(f\"\\nComparing Accuracy and Predictions for {onnx_path}\")\n",
    "    \n",
    "    session = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    model.eval()\n",
    "    correct_torch = 0\n",
    "    correct_onnx = 0\n",
    "    total = 0\n",
    "    \n",
    "    max_diff_logits = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # PyTorch (Output is Logits)\n",
    "            logits_torch = model(data)\n",
    "            _, predicted_torch = torch.max(logits_torch.data, 1)\n",
    "            correct_torch += (predicted_torch == target).sum().item()\n",
    "            \n",
    "            # ONNX (Output is Logits)\n",
    "            data_np = data.numpy()\n",
    "            logits_onnx = session.run(None, {input_name: data_np})[0]\n",
    "            predicted_onnx = np.argmax(logits_onnx, axis=1)\n",
    "            correct_onnx += (predicted_onnx == target.numpy()).sum().item()\n",
    "            \n",
    "            # Diff on logits\n",
    "            diff = np.abs(logits_torch.numpy() - logits_onnx)\n",
    "            max_diff_logits = max(max_diff_logits, np.max(diff))\n",
    "            \n",
    "            total += target.size(0)\n",
    "            \n",
    "            # Compare Soft predictions (Probabilities) for the first batch\n",
    "            if total == target.size(0): \n",
    "                 print(f\"Comparing soft predictions (Probabilities) for first {num_samples} samples:\")\n",
    "                 \n",
    "                 # Apply Softmax to convert Logits -> Probs for display\n",
    "                 probs_torch = F.softmax(logits_torch, dim=1).numpy()\n",
    "                 # For numpy/ONNX, we implement softmax manually or use torch's\n",
    "                 probs_onnx = F.softmax(torch.from_numpy(logits_onnx), dim=1).numpy()\n",
    "                 \n",
    "                 for i in range(num_samples):\n",
    "                     p_t = probs_torch[i]\n",
    "                     p_o = probs_onnx[i]\n",
    "                     \n",
    "                     top3_t = np.argsort(p_t)[-3:][::-1]\n",
    "                     top3_o = np.argsort(p_o)[-3:][::-1]\n",
    "                     \n",
    "                     print(f\"Sample {i}:\")\n",
    "                     print(f\"  PyTorch Top-3: {top3_t} Probs: {p_t[top3_t]}\")\n",
    "                     print(f\"  ONNX    Top-3: {top3_o} Probs: {p_o[top3_o]}\")\n",
    "                     print(f\"  Max Diff (Probs): {np.max(np.abs(p_t - p_o)):.8f}\")\n",
    "\n",
    "    acc_torch = 100 * correct_torch / total\n",
    "    acc_onnx = 100 * correct_onnx / total\n",
    "    \n",
    "    print(f\"\\nPyTorch Accuracy: {acc_torch:.2f}%\")\n",
    "    print(f\"ONNX Accuracy:    {acc_onnx:.2f}%\")\n",
    "    print(f\"Max Absolute Difference (Logits): {max_diff_logits:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96b2398-7549-4f47-9440-2e9185c6fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_and_analyze(original_onnx_path, dataset_name, test_loader, input_shape, batch_sizes):\n",
    "    print(f\"\\nQuantizing model: {original_onnx_path}\")\n",
    "    quantized_model_path = f\"model_torch_{dataset_name}.quant.onnx\"\n",
    "    \n",
    "    quantize_dynamic(\n",
    "        model_input=original_onnx_path,\n",
    "        model_output=quantized_model_path,\n",
    "        weight_type=QuantType.QUInt8\n",
    "    )\n",
    "    \n",
    "    orig_size = os.path.getsize(original_onnx_path)\n",
    "    quant_size = os.path.getsize(quantized_model_path)\n",
    "    print(f\"Original Model Size: {orig_size/1024/1024:.2f} MB\")\n",
    "    print(f\"Quantized Model Size: {quant_size/1024/1024:.2f} MB\")\n",
    "    print(f\"Compression Ratio: {orig_size/quant_size:.2f}x\")\n",
    "    \n",
    "    print(\"\\nBenchmarking Quantized Model:\")\n",
    "    sess_options = ort.SessionOptions()\n",
    "    session = ort.InferenceSession(quantized_model_path, sess_options, providers=['CPUExecutionProvider'])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    \n",
    "    all_data = []\n",
    "    for data, _ in test_loader:\n",
    "        all_data.append(data)\n",
    "        if len(all_data) * test_loader.batch_size > 200:\n",
    "            break\n",
    "    x_test = torch.cat(all_data, dim=0).numpy()\n",
    "    \n",
    "    print(f\"{ 'Batch Size':<12} | { 'Quantized (ms)':<15}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for bs in batch_sizes:\n",
    "        batch_data = x_test[:bs]\n",
    "        if batch_data.shape[0] < bs:\n",
    "             padding = np.zeros((bs - batch_data.shape[0], *input_shape), dtype=np.float32)\n",
    "             batch_data = np.concatenate([batch_data, padding], axis=0)\n",
    "             \n",
    "        session.run(None, {input_name: batch_data})\n",
    "        start = time.time()\n",
    "        for _ in range(10):\n",
    "            session.run(None, {input_name: batch_data})\n",
    "        end = time.time()\n",
    "        quant_time = (end - start) / 10 * 1000\n",
    "        print(f\"{bs:<12} | {quant_time:<15.4f}\")\n",
    "        \n",
    "    return quantized_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd99289e-42a7-428b-9ea1-020498de3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(dataset_name):\n",
    "    print(f\"\\n{'='*20} Running Pipeline for {dataset_name} {'='*20}\")\n",
    "    \n",
    "    train_loader, test_loader, input_shape, num_classes = get_data_loaders(dataset_name)\n",
    "    model = build_and_train(dataset_name, train_loader, epochs=5)\n",
    "    \n",
    "    onnx_path = convert_to_onnx(model, dataset_name, input_shape)\n",
    "    \n",
    "    benchmark_models(model, onnx_path, test_loader, input_shape)\n",
    "    compare_accuracy_and_soft(model, onnx_path, test_loader)\n",
    "    \n",
    "    quant_path = quantize_and_analyze(onnx_path, dataset_name, test_loader, input_shape, [1, 8, 32, 128])\n",
    "    \n",
    "    print(\"\\nVerifying Quantized Model Accuracy:\")\n",
    "    session = ort.InferenceSession(quant_path, providers=['CPUExecutionProvider'])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in test_loader:\n",
    "        data_np = data.numpy()\n",
    "        logits = session.run(None, {input_name: data_np})[0]\n",
    "        predicted = np.argmax(logits, axis=1)\n",
    "        correct += (predicted == target.numpy()).sum().item()\n",
    "        total += target.size(0)\n",
    "    print(f\"Quantized ONNX Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c66c93b-f215-484e-ac45-c70893ff05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Running Pipeline for mnist ====================\n",
      "Loading mnist...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.289583\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.372442\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.231600\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.231089\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmnist\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(dataset_name)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Running Pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m train_loader, test_loader, input_shape, num_classes = get_data_loaders(dataset_name)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mbuild_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m onnx_path = convert_to_onnx(model, dataset_name, input_shape)\n\u001b[32m      9\u001b[39m benchmark_models(model, onnx_path, test_loader, input_shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mbuild_and_train\u001b[39m\u001b[34m(dataset_name, train_loader, epochs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m torch.save(model.state_dict(), model_path)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel saved.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, device, train_loader, optimizer, epoch)\u001b[39m\n\u001b[32m      5\u001b[39m data, target = data.to(device), target.to(device)\n\u001b[32m      6\u001b[39m optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m loss = criterion(output, target)\n\u001b[32m      9\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/mlops/quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/mlops/quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mMnistNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     x = F.relu(x)\n\u001b[32m     14\u001b[39m     x = F.max_pool2d(x, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/mlops/quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/mlops/quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/mlops/quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/mlops/quantization/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_pipeline('mnist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "quant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
